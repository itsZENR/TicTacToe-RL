{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMx6tTFoeE9Nnvs/ooO/6GM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsZENR/TicTacToe-RL/blob/two_model/TicTacToe_RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Библиотеки\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "dB3h98NBD3Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TicTacToeEnvironment:\n",
        "    def __init__(self):\n",
        "        self.state = np.zeros((3, 3), dtype=int)\n",
        "        self.current_player = 1\n",
        "        self.done = False\n",
        "\n",
        "    def get_state(self):\n",
        "        return self.state.copy()\n",
        "\n",
        "    def get_valid_actions(self):\n",
        "        return np.where(self.state.flatten() == 0)[0]\n",
        "\n",
        "    def step(self, action, current_player):\n",
        "        self.current_player = current_player\n",
        "        if self.done:\n",
        "            raise ValueError(\"Game is already finished\")\n",
        "\n",
        "        i, j = np.unravel_index(action, (3, 3))\n",
        "        if self.state[i, j] != 0:\n",
        "            raise ValueError(\"Invalid action\")\n",
        "\n",
        "        self.state[i, j] = self.current_player\n",
        "        winner = self.get_winner()\n",
        "        if winner is not None or np.all(self.state != 0):\n",
        "            self.done = True\n",
        "\n",
        "        reward = 0\n",
        "        if winner is not None:\n",
        "            reward = 1 if winner == 1 else -1\n",
        "\n",
        "        return self.get_state(), reward, self.done\n",
        "\n",
        "    def step_game_player(self, action):\n",
        "        if self.done:\n",
        "              raise ValueError(\"Game is already finished\")\n",
        "\n",
        "        i, j = np.unravel_index(action, (3, 3))\n",
        "        if self.state[i, j] != 0:\n",
        "            raise ValueError(\"Invalid action\")\n",
        "\n",
        "        self.state[i, j] = self.current_player\n",
        "        winner = self.get_winner()\n",
        "        if winner is not None or np.all(self.state != 0):\n",
        "            self.done = True\n",
        "\n",
        "        reward = 0\n",
        "        if winner is not None:\n",
        "            reward = 1 if winner == 1 else -1\n",
        "\n",
        "        return self.get_state(), reward, self.done\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.zeros((3, 3), dtype=int)\n",
        "        self.current_player = 1\n",
        "        self.done = False\n",
        "\n",
        "    def get_winner(self):\n",
        "\n",
        "        # Check rows\n",
        "        for i in range(3):\n",
        "            if np.all(self.state[i, :] == 1):\n",
        "                return 1\n",
        "            elif np.all(self.state[i, :] == -1):\n",
        "                return -1\n",
        "\n",
        "        # Check columns\n",
        "        for j in range(3):\n",
        "            if np.all(self.state[:, j] == 1):\n",
        "                return 1\n",
        "            elif np.all(self.state[:, j] == -1):\n",
        "                return -1\n",
        "\n",
        "        # Check diagonals\n",
        "        if np.all(np.diag(self.state) == 1) or np.all(np.diag(np.fliplr(self.state)) == 1):\n",
        "            return 1\n",
        "        elif np.all(np.diag(self.state) == -1) or np.all(np.diag(np.fliplr(self.state)) == -1):\n",
        "            return -1\n",
        "\n",
        "        # Check tie\n",
        "        if np.all(self.state != 0):\n",
        "            return 0\n",
        "\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "0tqzNPRclvYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение модели Q-функции\n",
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(125, activation='relu', input_shape=(9,)),\n",
        "    tf.keras.layers.Dense(9)\n",
        "])\n",
        "\n",
        "model_1.compile(optimizer='Adam', loss=tf.keras.losses.BinaryCrossentropy())\n",
        "\n",
        "# Определение модели Q-функции\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(125, activation='relu', input_shape=(9,)),\n",
        "    tf.keras.layers.Dense(9)\n",
        "])\n",
        "\n",
        "model_2.compile(optimizer='Adam', loss=tf.keras.losses.BinaryCrossentropy())"
      ],
      "metadata": {
        "id": "4tBQZhlVmhaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение функции выбора действия\n",
        "def choose_action(state, epsilon, model):\n",
        "    if np.random.random() < epsilon:\n",
        "        # Случайное действие\n",
        "        action = np.random.choice(np.where(env.state.flatten() == 0)[0])\n",
        "    else:\n",
        "        # Выбор действия с наибольшим значением Q-функции\n",
        "        q_values = model.predict(state.reshape(1, -1))\n",
        "        action = np.argmax(q_values[0] * (env.state.flatten() == 0))\n",
        "        print('q_values', q_values)\n",
        "    return action\n",
        "\n",
        "# Определение функции обновления Q-функции\n",
        "def update_q_function(state, action, reward, next_state, alpha, gamma, model):\n",
        "    q_values = model.predict(state.reshape(1, -1), verbose=0)\n",
        "    next_q_values = model.predict(next_state.reshape(1, -1), verbose=0)\n",
        "    if model == model_2:\n",
        "      reward = -reward\n",
        "    td_target = reward + gamma * np.amax(next_q_values)\n",
        "    td_error = td_target - q_values[0][action]\n",
        "    q_values[0][action] += alpha * td_error\n",
        "    model.fit(state.reshape(1, -1), q_values)\n",
        "\n",
        "# Основной цикл обучения\n",
        "num_episodes = 100\n",
        "epsilon = 1.0\n",
        "epsilon_decay = 0.9995\n",
        "alpha = 0.01\n",
        "gamma = 0.99\n",
        "\n",
        "for i in range(num_episodes):\n",
        "    print(i, '-'*100)\n",
        "    env = TicTacToeEnvironment()\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = choose_action(env.state, epsilon, model_1)\n",
        "        update_q_function(env.state, action, reward, next_state, alpha, gamma, model_1)\n",
        "        next_state, reward, done = env.step(action, current_player=1)\n",
        "        print(\"action\", action)\n",
        "        print(next_state)\n",
        "        print('reward:', reward)\n",
        "        print('done:', done)\n",
        "        env.state = next_state\n",
        "\n",
        "        if not done:\n",
        "          action = choose_action(env.state, epsilon, model_2)\n",
        "          update_q_function(env.state, action, reward, next_state, alpha, gamma, model_2)\n",
        "          next_state, reward, done = env.step(action, current_player=-1)\n",
        "          print(\"action\", action)\n",
        "          print(next_state)\n",
        "          print('reward:', reward)\n",
        "          print('done:', done)\n",
        "          env.state = next_state\n",
        "\n",
        "\n",
        "    epsilon *= epsilon_decay"
      ],
      "metadata": {
        "id": "x_LcTrHwj2h1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e6e9e5-ca92-4c32-f124-1207da116c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            " [ 0  1 -1]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0649\n",
            "action 0\n",
            "[[ 1  0 -1]\n",
            " [ 0  1 -1]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.2854\n",
            "action 3\n",
            "[[ 1  0 -1]\n",
            " [-1  1 -1]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0788\n",
            "action 8\n",
            "[[ 1  0 -1]\n",
            " [-1  1 -1]\n",
            " [ 0  1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "9 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0725\n",
            "action 7\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.4858\n",
            "action 3\n",
            "[[ 0  0  0]\n",
            " [-1  0  0]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.0922\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [-1  1  0]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -1.2462\n",
            "action 5\n",
            "[[ 0  0  0]\n",
            " [-1  1 -1]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3127\n",
            "action 1\n",
            "[[ 0  1  0]\n",
            " [-1  1 -1]\n",
            " [ 0  1  0]]\n",
            "reward: 1\n",
            "done: True\n",
            "10 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0745\n",
            "action 1\n",
            "[[0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.4872\n",
            "action 4\n",
            "[[ 0  1  0]\n",
            " [ 0 -1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0717\n",
            "action 3\n",
            "[[ 0  1  0]\n",
            " [ 1 -1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 12ms/step - loss: -0.6023\n",
            "action 2\n",
            "[[ 0  1 -1]\n",
            " [ 1 -1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4394\n",
            "action 0\n",
            "[[ 1  1 -1]\n",
            " [ 1 -1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.7010\n",
            "action 7\n",
            "[[ 1  1 -1]\n",
            " [ 1 -1  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0204\n",
            "action 5\n",
            "[[ 1  1 -1]\n",
            " [ 1 -1  1]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.6546\n",
            "action 8\n",
            "[[ 1  1 -1]\n",
            " [ 1 -1  1]\n",
            " [ 0 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.3381\n",
            "action 6\n",
            "[[ 1  1 -1]\n",
            " [ 1 -1  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "11 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0842\n",
            "action 8\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 12ms/step - loss: -0.5330\n",
            "action 6\n",
            "[[ 0  0  0]\n",
            " [ 0  0  0]\n",
            " [-1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.4778\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [ 0  1  0]\n",
            " [-1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -2.2277\n",
            "action 5\n",
            "[[ 0  0  0]\n",
            " [ 0  1 -1]\n",
            " [-1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0127\n",
            "action 1\n",
            "[[ 0  1  0]\n",
            " [ 0  1 -1]\n",
            " [-1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -3.0519\n",
            "action 0\n",
            "[[-1  1  0]\n",
            " [ 0  1 -1]\n",
            " [-1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0319\n",
            "action 2\n",
            "[[-1  1  1]\n",
            " [ 0  1 -1]\n",
            " [-1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -3.4869\n",
            "action 3\n",
            "[[-1  1  1]\n",
            " [-1  1 -1]\n",
            " [-1  0  1]]\n",
            "reward: -1\n",
            "done: True\n",
            "12 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0812\n",
            "action 2\n",
            "[[0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.3746\n",
            "action 7\n",
            "[[ 0  0  1]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: -0.1515\n",
            "action 1\n",
            "[[ 0  1  1]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -0.5306\n",
            "action 6\n",
            "[[ 0  1  1]\n",
            " [ 0  0  0]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 12ms/step - loss: -0.3451\n",
            "action 3\n",
            "[[ 0  1  1]\n",
            " [ 1  0  0]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -1.2062\n",
            "action 4\n",
            "[[ 0  1  1]\n",
            " [ 1 -1  0]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.1756\n",
            "action 8\n",
            "[[ 0  1  1]\n",
            " [ 1 -1  0]\n",
            " [-1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -1.0507\n",
            "action 5\n",
            "[[ 0  1  1]\n",
            " [ 1 -1 -1]\n",
            " [-1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0993\n",
            "action 0\n",
            "[[ 1  1  1]\n",
            " [ 1 -1 -1]\n",
            " [-1 -1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "13 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0928\n",
            "action 1\n",
            "[[0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.4337\n",
            "action 3\n",
            "[[ 0  1  0]\n",
            " [-1  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.1079\n",
            "action 0\n",
            "[[ 1  1  0]\n",
            " [-1  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.1829\n",
            "action 7\n",
            "[[ 1  1  0]\n",
            " [-1  0  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -0.2220\n",
            "action 8\n",
            "[[ 1  1  0]\n",
            " [-1  0  0]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.0925\n",
            "action 6\n",
            "[[ 1  1  0]\n",
            " [-1  0  0]\n",
            " [-1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.5009\n",
            "action 2\n",
            "[[ 1  1  1]\n",
            " [-1  0  0]\n",
            " [-1 -1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "14 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0959\n",
            "action 8\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.5005\n",
            "action 7\n",
            "[[ 0  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: -0.3418\n",
            "action 0\n",
            "[[ 1  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 13ms/step - loss: -0.6443\n",
            "action 2\n",
            "[[ 1  0 -1]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.4311\n",
            "action 3\n",
            "[[ 1  0 -1]\n",
            " [ 1  0  0]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 13ms/step - loss: -0.7089\n",
            "action 4\n",
            "[[ 1  0 -1]\n",
            " [ 1 -1  0]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 14ms/step - loss: -0.5120\n",
            "action 5\n",
            "[[ 1  0 -1]\n",
            " [ 1 -1  1]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.6954\n",
            "action 6\n",
            "[[ 1  0 -1]\n",
            " [ 1 -1  1]\n",
            " [-1 -1  1]]\n",
            "reward: -1\n",
            "done: True\n",
            "15 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0939\n",
            "action 5\n",
            "[[0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1475\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 0  0  1]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -0.3652\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [ 0  1  1]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.5381\n",
            "action 7\n",
            "[[ 0  0  0]\n",
            " [ 0  1  1]\n",
            " [ 0 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.3184\n",
            "action 0\n",
            "[[ 1  0  0]\n",
            " [ 0  1  1]\n",
            " [ 0 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.3498\n",
            "action 1\n",
            "[[ 1 -1  0]\n",
            " [ 0  1  1]\n",
            " [ 0 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.4910\n",
            "action 3\n",
            "[[ 1 -1  0]\n",
            " [ 1  1  1]\n",
            " [ 0 -1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "16 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1055\n",
            "action 3\n",
            "[[0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.2105\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 1  0  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1847\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [ 1  1  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.4729\n",
            "action 2\n",
            "[[ 0  0 -1]\n",
            " [ 1  1  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1020\n",
            "action 5\n",
            "[[ 0  0 -1]\n",
            " [ 1  1  1]\n",
            " [ 0  0 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "17 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1081\n",
            "action 7\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.4039\n",
            "action 0\n",
            "[[-1  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0511\n",
            "action 6\n",
            "[[-1  0  0]\n",
            " [ 0  0  0]\n",
            " [ 1  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.8374\n",
            "action 3\n",
            "[[-1  0  0]\n",
            " [-1  0  0]\n",
            " [ 1  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.7031\n",
            "action 5\n",
            "[[-1  0  0]\n",
            " [-1  0  1]\n",
            " [ 1  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -0.7481\n",
            "action 8\n",
            "[[-1  0  0]\n",
            " [-1  0  1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -1.1700\n",
            "action 1\n",
            "[[-1  1  0]\n",
            " [-1  0  1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.6102\n",
            "action 2\n",
            "[[-1  1 -1]\n",
            " [-1  0  1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.8130\n",
            "action 4\n",
            "[[-1  1 -1]\n",
            " [-1  1  1]\n",
            " [ 1  1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "18 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1104\n",
            "action 1\n",
            "[[0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.3564\n",
            "action 2\n",
            "[[ 0  1 -1]\n",
            " [ 0  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3590\n",
            "action 4\n",
            "[[ 0  1 -1]\n",
            " [ 0  1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.4458\n",
            "action 8\n",
            "[[ 0  1 -1]\n",
            " [ 0  1  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2126\n",
            "action 7\n",
            "[[ 0  1 -1]\n",
            " [ 0  1  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "19 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1136\n",
            "action 7\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.3989\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [ 0 -1  0]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3466\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 0 -1  0]\n",
            " [ 0  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.8473\n",
            "action 3\n",
            "[[ 0  0  0]\n",
            " [-1 -1  0]\n",
            " [ 0  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0773\n",
            "action 6\n",
            "[[ 0  0  0]\n",
            " [-1 -1  0]\n",
            " [ 1  1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "20 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1150\n",
            "action 0\n",
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0074\n",
            "action 7\n",
            "[[ 1  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0122\n",
            "action 2\n",
            "[[ 1  0  1]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.2711\n",
            "action 4\n",
            "[[ 1  0  1]\n",
            " [ 0 -1  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.4373\n",
            "action 1\n",
            "[[ 1  1  1]\n",
            " [ 0 -1  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 1\n",
            "done: True\n",
            "21 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1185\n",
            "action 5\n",
            "[[0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1502\n",
            "action 7\n",
            "[[ 0  0  0]\n",
            " [ 0  0  1]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.5926\n",
            "action 1\n",
            "[[ 0  1  0]\n",
            " [ 0  0  1]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2703\n",
            "action 3\n",
            "[[ 0  1  0]\n",
            " [-1  0  1]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.7122\n",
            "action 8\n",
            "[[ 0  1  0]\n",
            " [-1  0  1]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.3929\n",
            "action 2\n",
            "[[ 0  1 -1]\n",
            " [-1  0  1]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -0.4609\n",
            "action 4\n",
            "[[ 0  1 -1]\n",
            " [-1  1  1]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.4724\n",
            "action 0\n",
            "[[-1  1 -1]\n",
            " [-1  1  1]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -1.0299\n",
            "action 6\n",
            "[[-1  1 -1]\n",
            " [-1  1  1]\n",
            " [ 1 -1  1]]\n",
            "reward: -1\n",
            "done: True\n",
            "22 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1154\n",
            "action 2\n",
            "[[0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.2698\n",
            "action 3\n",
            "[[ 0  0  1]\n",
            " [-1  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.1630\n",
            "action 0\n",
            "[[ 1  0  1]\n",
            " [-1  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.0793\n",
            "action 1\n",
            "[[ 1 -1  1]\n",
            " [-1  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.1285\n",
            "action 7\n",
            "[[ 1 -1  1]\n",
            " [-1  0  0]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.4283\n",
            "action 5\n",
            "[[ 1 -1  1]\n",
            " [-1  0 -1]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3800\n",
            "action 6\n",
            "[[ 1 -1  1]\n",
            " [-1  0 -1]\n",
            " [ 1  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.8109\n",
            "action 8\n",
            "[[ 1 -1  1]\n",
            " [-1  0 -1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.2801\n",
            "action 4\n",
            "[[ 1 -1  1]\n",
            " [-1  1 -1]\n",
            " [ 1  1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "23 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1580\n",
            "action 4\n",
            "[[0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.7810\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 0  1  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1771\n",
            "action 2\n",
            "[[ 0  0  1]\n",
            " [ 0  1  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -1.3563\n",
            "action 3\n",
            "[[ 0  0  1]\n",
            " [-1  1  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.2951\n",
            "action 5\n",
            "[[ 0  0  1]\n",
            " [-1  1  1]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.6222\n",
            "action 1\n",
            "[[ 0 -1  1]\n",
            " [-1  1  1]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.9342\n",
            "action 6\n",
            "[[ 0 -1  1]\n",
            " [-1  1  1]\n",
            " [ 1  0 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "24 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1534\n",
            "action 4\n",
            "[[0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.7180\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 0  1  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1812\n",
            "action 2\n",
            "[[ 0  0  1]\n",
            " [ 0  1  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.2344\n",
            "action 6\n",
            "[[ 0  0  1]\n",
            " [ 0  1  0]\n",
            " [-1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0321\n",
            "action 5\n",
            "[[ 0  0  1]\n",
            " [ 0  1  1]\n",
            " [-1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -1.4175\n",
            "action 7\n",
            "[[ 0  0  1]\n",
            " [ 0  1  1]\n",
            " [-1 -1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "25 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1168\n",
            "action 4\n",
            "[[0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -0.6707\n",
            "action 1\n",
            "[[ 0 -1  0]\n",
            " [ 0  1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -0.1335\n",
            "action 8\n",
            "[[ 0 -1  0]\n",
            " [ 0  1  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.1479\n",
            "action 3\n",
            "[[ 0 -1  0]\n",
            " [-1  1  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: -0.4197\n",
            "action 0\n",
            "[[ 1 -1  0]\n",
            " [-1  1  0]\n",
            " [ 0  0  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "26 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1477\n",
            "action 4\n",
            "[[0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.6386\n",
            "action 3\n",
            "[[ 0  0  0]\n",
            " [-1  1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0369\n",
            "action 5\n",
            "[[ 0  0  0]\n",
            " [-1  1  1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: -0.5055\n",
            "action 1\n",
            "[[ 0 -1  0]\n",
            " [-1  1  1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.4442\n",
            "action 6\n",
            "[[ 0 -1  0]\n",
            " [-1  1  1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.8480\n",
            "action 8\n",
            "[[ 0 -1  0]\n",
            " [-1  1  1]\n",
            " [ 1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.7298\n",
            "action 7\n",
            "[[ 0 -1  0]\n",
            " [-1  1  1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.8837\n",
            "action 0\n",
            "[[-1 -1  0]\n",
            " [-1  1  1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -1.3712\n",
            "action 2\n",
            "[[-1 -1  1]\n",
            " [-1  1  1]\n",
            " [ 1  1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "27 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1312\n",
            "action 2\n",
            "[[0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.0366\n",
            "action 3\n",
            "[[ 0  0  1]\n",
            " [-1  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.0343\n",
            "action 6\n",
            "[[ 0  0  1]\n",
            " [-1  0  0]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.2442\n",
            "action 7\n",
            "[[ 0  0  1]\n",
            " [-1  0  0]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -0.3194\n",
            "action 8\n",
            "[[ 0  0  1]\n",
            " [-1  0  0]\n",
            " [ 1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.8799\n",
            "action 5\n",
            "[[ 0  0  1]\n",
            " [-1  0 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.1353\n",
            "action 0\n",
            "[[ 1  0  1]\n",
            " [-1  0 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.7414\n",
            "action 1\n",
            "[[ 1 -1  1]\n",
            " [-1  0 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.1237\n",
            "action 4\n",
            "[[ 1 -1  1]\n",
            " [-1  1 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "28 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1378\n",
            "action 6\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.0154\n",
            "action 5\n",
            "[[ 0  0  0]\n",
            " [ 0  0 -1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1318\n",
            "action 3\n",
            "[[ 0  0  0]\n",
            " [ 1  0 -1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.7258\n",
            "action 2\n",
            "[[ 0  0 -1]\n",
            " [ 1  0 -1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -0.3380\n",
            "action 7\n",
            "[[ 0  0 -1]\n",
            " [ 1  0 -1]\n",
            " [ 1  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.7349\n",
            "action 0\n",
            "[[-1  0 -1]\n",
            " [ 1  0 -1]\n",
            " [ 1  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0315\n",
            "action 8\n",
            "[[-1  0 -1]\n",
            " [ 1  0 -1]\n",
            " [ 1  1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "29 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1429\n",
            "action 3\n",
            "[[0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -0.0375\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 1  0  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2317\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [ 1  1  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -1.0270\n",
            "action 6\n",
            "[[ 0  0  0]\n",
            " [ 1  1  0]\n",
            " [-1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2746\n",
            "action 0\n",
            "[[ 1  0  0]\n",
            " [ 1  1  0]\n",
            " [-1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -1.4103\n",
            "action 7\n",
            "[[ 1  0  0]\n",
            " [ 1  1  0]\n",
            " [-1 -1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "30 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1394\n",
            "action 0\n",
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2385\n",
            "action 4\n",
            "[[ 1  0  0]\n",
            " [ 0 -1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1023\n",
            "action 6\n",
            "[[ 1  0  0]\n",
            " [ 0 -1  0]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2372\n",
            "action 7\n",
            "[[ 1  0  0]\n",
            " [ 0 -1  0]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -0.1985\n",
            "action 5\n",
            "[[ 1  0  0]\n",
            " [ 0 -1  1]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1185\n",
            "action 8\n",
            "[[ 1  0  0]\n",
            " [ 0 -1  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.6317\n",
            "action 3\n",
            "[[ 1  0  0]\n",
            " [ 1 -1  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "31 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1497\n",
            "action 5\n",
            "[[0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2918\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [ 0 -1  1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.3861\n",
            "action 6\n",
            "[[ 0  0  0]\n",
            " [ 0 -1  1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2327\n",
            "action 2\n",
            "[[ 0  0 -1]\n",
            " [ 0 -1  1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.2779\n",
            "action 0\n",
            "[[ 1  0 -1]\n",
            " [ 0 -1  1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -0.0378\n",
            "action 7\n",
            "[[ 1  0 -1]\n",
            " [ 0 -1  1]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.3241\n",
            "action 3\n",
            "[[ 1  0 -1]\n",
            " [ 1 -1  1]\n",
            " [ 1 -1  0]]\n",
            "reward: 1\n",
            "done: True\n",
            "32 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1778\n",
            "action 4\n",
            "[[0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.3228\n",
            "action 3\n",
            "[[ 0  0  0]\n",
            " [-1  1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1223\n",
            "action 2\n",
            "[[ 0  0  1]\n",
            " [-1  1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.5310\n",
            "action 0\n",
            "[[-1  0  1]\n",
            " [-1  1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.0772\n",
            "action 5\n",
            "[[-1  0  1]\n",
            " [-1  1  1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.5295\n",
            "action 7\n",
            "[[-1  0  1]\n",
            " [-1  1  1]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.8942\n",
            "action 1\n",
            "[[-1  1  1]\n",
            " [-1  1  1]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -0.5868\n",
            "action 8\n",
            "[[-1  1  1]\n",
            " [-1  1  1]\n",
            " [ 0 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -1.7127\n",
            "action 6\n",
            "[[-1  1  1]\n",
            " [-1  1  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "33 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1570\n",
            "action 8\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.1631\n",
            "action 5\n",
            "[[ 0  0  0]\n",
            " [ 0  0 -1]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3492\n",
            "action 3\n",
            "[[ 0  0  0]\n",
            " [ 1  0 -1]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.7579\n",
            "action 2\n",
            "[[ 0  0 -1]\n",
            " [ 1  0 -1]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.0393\n",
            "action 7\n",
            "[[ 0  0 -1]\n",
            " [ 1  0 -1]\n",
            " [ 0  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.7610\n",
            "action 1\n",
            "[[ 0 -1 -1]\n",
            " [ 1  0 -1]\n",
            " [ 0  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.1504\n",
            "action 0\n",
            "[[ 1 -1 -1]\n",
            " [ 1  0 -1]\n",
            " [ 0  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.6300\n",
            "action 6\n",
            "[[ 1 -1 -1]\n",
            " [ 1  0 -1]\n",
            " [-1  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2439\n",
            "action 4\n",
            "[[ 1 -1 -1]\n",
            " [ 1  1 -1]\n",
            " [-1  1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "34 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1601\n",
            "action 5\n",
            "[[0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3299\n",
            "action 2\n",
            "[[ 0  0 -1]\n",
            " [ 0  0  1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.1130\n",
            "action 6\n",
            "[[ 0  0 -1]\n",
            " [ 0  0  1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1063\n",
            "action 4\n",
            "[[ 0  0 -1]\n",
            " [ 0 -1  1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.2311\n",
            "action 0\n",
            "[[ 1  0 -1]\n",
            " [ 0 -1  1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0060\n",
            "action 3\n",
            "[[ 1  0 -1]\n",
            " [-1 -1  1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -0.2657\n",
            "action 8\n",
            "[[ 1  0 -1]\n",
            " [-1 -1  1]\n",
            " [ 1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: -0.2897\n",
            "action 1\n",
            "[[ 1 -1 -1]\n",
            " [-1 -1  1]\n",
            " [ 1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 13ms/step - loss: -0.6806\n",
            "action 7\n",
            "[[ 1 -1 -1]\n",
            " [-1 -1  1]\n",
            " [ 1  1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "35 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1626\n",
            "action 7\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0811\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1122\n",
            "action 1\n",
            "[[ 0  1  0]\n",
            " [ 0  0  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.0884\n",
            "action 0\n",
            "[[-1  1  0]\n",
            " [ 0  0  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1255\n",
            "action 4\n",
            "[[-1  1  0]\n",
            " [ 0  1  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "36 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1661\n",
            "action 6\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0789\n",
            "action 7\n",
            "[[ 0  0  0]\n",
            " [ 0  0  0]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0892\n",
            "action 1\n",
            "[[ 0  1  0]\n",
            " [ 0  0  0]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0757\n",
            "action 8\n",
            "[[ 0  1  0]\n",
            " [ 0  0  0]\n",
            " [ 1 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.1850\n",
            "action 3\n",
            "[[ 0  1  0]\n",
            " [ 1  0  0]\n",
            " [ 1 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2683\n",
            "action 2\n",
            "[[ 0  1 -1]\n",
            " [ 1  0  0]\n",
            " [ 1 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.1151\n",
            "action 4\n",
            "[[ 0  1 -1]\n",
            " [ 1  1  0]\n",
            " [ 1 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3524\n",
            "action 5\n",
            "[[ 0  1 -1]\n",
            " [ 1  1 -1]\n",
            " [ 1 -1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "37 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1635\n",
            "action 6\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1085\n",
            "action 2\n",
            "[[ 0  0 -1]\n",
            " [ 0  0  0]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1570\n",
            "action 4\n",
            "[[ 0  0 -1]\n",
            " [ 0  1  0]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.0063\n",
            "action 5\n",
            "[[ 0  0 -1]\n",
            " [ 0  1 -1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.0989\n",
            "action 1\n",
            "[[ 0  1 -1]\n",
            " [ 0  1 -1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1161\n",
            "action 7\n",
            "[[ 0  1 -1]\n",
            " [ 0  1 -1]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0495\n",
            "action 8\n",
            "[[ 0  1 -1]\n",
            " [ 0  1 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.5078\n",
            "action 0\n",
            "[[-1  1 -1]\n",
            " [ 0  1 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.4653\n",
            "action 3\n",
            "[[-1  1 -1]\n",
            " [ 1  1 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: -1\n",
            "done: True\n",
            "38 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "q_values [[ 0.05066139  0.08526257  0.06524222  0.04300702 -0.01994149  0.05524934\n",
            "   0.05677553  0.06067741  0.06284656]]\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1663\n",
            "action 1\n",
            "[[0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -0.0459\n",
            "action 4\n",
            "[[ 0  1  0]\n",
            " [ 0 -1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2321\n",
            "action 6\n",
            "[[ 0  1  0]\n",
            " [ 0 -1  0]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0666\n",
            "action 7\n",
            "[[ 0  1  0]\n",
            " [ 0 -1  0]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.0017\n",
            "action 0\n",
            "[[ 1  1  0]\n",
            " [ 0 -1  0]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4287\n",
            "action 5\n",
            "[[ 1  1  0]\n",
            " [ 0 -1 -1]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2298\n",
            "action 8\n",
            "[[ 1  1  0]\n",
            " [ 0 -1 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0983\n",
            "action 2\n",
            "[[ 1  1 -1]\n",
            " [ 0 -1 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2993\n",
            "action 3\n",
            "[[ 1  1 -1]\n",
            " [ 1 -1 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "39 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1748\n",
            "action 0\n",
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3736\n",
            "action 1\n",
            "[[ 1 -1  0]\n",
            " [ 0  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.0241\n",
            "action 5\n",
            "[[ 1 -1  0]\n",
            " [ 0  0  1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0348\n",
            "action 8\n",
            "[[ 1 -1  0]\n",
            " [ 0  0  1]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.4886\n",
            "action 2\n",
            "[[ 1 -1  1]\n",
            " [ 0  0  1]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.0553\n",
            "action 7\n",
            "[[ 1 -1  1]\n",
            " [ 0  0  1]\n",
            " [ 0 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 12ms/step - loss: -0.5939\n",
            "action 6\n",
            "[[ 1 -1  1]\n",
            " [ 0  0  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "q_values [[ 0.5527824   0.5771104  -0.45983538  0.49896467  0.6991853   0.7643053\n",
            "   0.22483537  0.32993388  0.6728037 ]]\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -0.2305\n",
            "action 4\n",
            "[[ 1 -1  1]\n",
            " [ 0 -1  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "40 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1705\n",
            "action 2\n",
            "[[0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1557\n",
            "action 7\n",
            "[[ 0  0  1]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0663\n",
            "action 5\n",
            "[[ 0  0  1]\n",
            " [ 0  0  1]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2620\n",
            "action 6\n",
            "[[ 0  0  1]\n",
            " [ 0  0  1]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.3599\n",
            "action 1\n",
            "[[ 0  1  1]\n",
            " [ 0  0  1]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0817\n",
            "action 4\n",
            "[[ 0  1  1]\n",
            " [ 0 -1  1]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.7114\n",
            "action 3\n",
            "[[ 0  1  1]\n",
            " [ 1 -1  1]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0501\n",
            "action 8\n",
            "[[ 0  1  1]\n",
            " [ 1 -1  1]\n",
            " [-1 -1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "41 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1726\n",
            "action 6\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1342\n",
            "action 1\n",
            "[[ 0 -1  0]\n",
            " [ 0  0  0]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1620\n",
            "action 5\n",
            "[[ 0 -1  0]\n",
            " [ 0  0  1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -0.0746\n",
            "action 2\n",
            "[[ 0 -1 -1]\n",
            " [ 0  0  1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 21ms/step - loss: -0.3459\n",
            "action 4\n",
            "[[ 0 -1 -1]\n",
            " [ 0  1  1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.2957\n",
            "action 8\n",
            "[[ 0 -1 -1]\n",
            " [ 0  1  1]\n",
            " [ 1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.4156\n",
            "action 7\n",
            "[[ 0 -1 -1]\n",
            " [ 0  1  1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.2991\n",
            "action 0\n",
            "[[-1 -1 -1]\n",
            " [ 0  1  1]\n",
            " [ 1  1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "42 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1743\n",
            "action 8\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0571\n",
            "action 1\n",
            "[[ 0 -1  0]\n",
            " [ 0  0  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.0725\n",
            "action 3\n",
            "[[ 0 -1  0]\n",
            " [ 1  0  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1164\n",
            "action 0\n",
            "[[-1 -1  0]\n",
            " [ 1  0  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.0867\n",
            "action 4\n",
            "[[-1 -1  0]\n",
            " [ 1  1  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -0.5945\n",
            "action 6\n",
            "[[-1 -1  0]\n",
            " [ 1  1  0]\n",
            " [-1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.1752\n",
            "action 2\n",
            "[[-1 -1  1]\n",
            " [ 1  1  0]\n",
            " [-1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -1.2806\n",
            "action 7\n",
            "[[-1 -1  1]\n",
            " [ 1  1  0]\n",
            " [-1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.1495\n",
            "action 5\n",
            "[[-1 -1  1]\n",
            " [ 1  1  1]\n",
            " [-1 -1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "43 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1811\n",
            "action 7\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2991\n",
            "action 0\n",
            "[[-1  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3220\n",
            "action 1\n",
            "[[-1  1  0]\n",
            " [ 0  0  0]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.6269\n",
            "action 6\n",
            "[[-1  1  0]\n",
            " [ 0  0  0]\n",
            " [-1  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4762\n",
            "action 8\n",
            "[[-1  1  0]\n",
            " [ 0  0  0]\n",
            " [-1  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -1.3169\n",
            "action 4\n",
            "[[-1  1  0]\n",
            " [ 0 -1  0]\n",
            " [-1  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4785\n",
            "action 3\n",
            "[[-1  1  0]\n",
            " [ 1 -1  0]\n",
            " [-1  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.4254\n",
            "action 5\n",
            "[[-1  1  0]\n",
            " [ 1 -1 -1]\n",
            " [-1  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4340\n",
            "action 2\n",
            "[[-1  1  1]\n",
            " [ 1 -1 -1]\n",
            " [-1  1  1]]\n",
            "reward: -1\n",
            "done: True\n",
            "44 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1741\n",
            "action 4\n",
            "[[0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0889\n",
            "action 5\n",
            "[[ 0  0  0]\n",
            " [ 0  1 -1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3236\n",
            "action 1\n",
            "[[ 0  1  0]\n",
            " [ 0  1 -1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.2215\n",
            "action 2\n",
            "[[ 0  1 -1]\n",
            " [ 0  1 -1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3617\n",
            "action 6\n",
            "[[ 0  1 -1]\n",
            " [ 0  1 -1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1372\n",
            "action 0\n",
            "[[-1  1 -1]\n",
            " [ 0  1 -1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -0.0922\n",
            "action 7\n",
            "[[-1  1 -1]\n",
            " [ 0  1 -1]\n",
            " [ 1  1  0]]\n",
            "reward: 1\n",
            "done: True\n",
            "45 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1777\n",
            "action 0\n",
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4096\n",
            "action 8\n",
            "[[ 1  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.0412\n",
            "action 4\n",
            "[[ 1  0  0]\n",
            " [ 0  1  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2978\n",
            "action 7\n",
            "[[ 1  0  0]\n",
            " [ 0  1  0]\n",
            " [ 0 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0912\n",
            "action 3\n",
            "[[ 1  0  0]\n",
            " [ 1  1  0]\n",
            " [ 0 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2162\n",
            "action 1\n",
            "[[ 1 -1  0]\n",
            " [ 1  1  0]\n",
            " [ 0 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.0986\n",
            "action 6\n",
            "[[ 1 -1  0]\n",
            " [ 1  1  0]\n",
            " [ 1 -1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "46 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1776\n",
            "action 8\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0884\n",
            "action 7\n",
            "[[ 0  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2006\n",
            "action 1\n",
            "[[ 0  1  0]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0665\n",
            "action 4\n",
            "[[ 0  1  0]\n",
            " [ 0 -1  0]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1287\n",
            "action 5\n",
            "[[ 0  1  0]\n",
            " [ 0 -1  1]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0884\n",
            "action 6\n",
            "[[ 0  1  0]\n",
            " [ 0 -1  1]\n",
            " [-1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.5908\n",
            "action 2\n",
            "[[ 0  1  1]\n",
            " [ 0 -1  1]\n",
            " [-1 -1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "47 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1794\n",
            "action 0\n",
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4161\n",
            "action 7\n",
            "[[ 1  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2803\n",
            "action 4\n",
            "[[ 1  0  0]\n",
            " [ 0  1  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0197\n",
            "action 5\n",
            "[[ 1  0  0]\n",
            " [ 0  1 -1]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3884\n",
            "action 6\n",
            "[[ 1  0  0]\n",
            " [ 0  1 -1]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: -0.1938\n",
            "action 1\n",
            "[[ 1 -1  0]\n",
            " [ 0  1 -1]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1357\n",
            "action 3\n",
            "[[ 1 -1  0]\n",
            " [ 1  1 -1]\n",
            " [ 1 -1  0]]\n",
            "reward: 1\n",
            "done: True\n",
            "48 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2049\n",
            "action 4\n",
            "[[0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1110\n",
            "action 3\n",
            "[[ 0  0  0]\n",
            " [-1  1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2033\n",
            "action 2\n",
            "[[ 0  0  1]\n",
            " [-1  1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.2201\n",
            "action 6\n",
            "[[ 0  0  1]\n",
            " [-1  1  0]\n",
            " [-1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.0984\n",
            "action 5\n",
            "[[ 0  0  1]\n",
            " [-1  1  1]\n",
            " [-1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: -0.0240\n",
            "action 8\n",
            "[[ 0  0  1]\n",
            " [-1  1  1]\n",
            " [-1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -1.0679\n",
            "action 7\n",
            "[[ 0  0  1]\n",
            " [-1  1  1]\n",
            " [-1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0194\n",
            "action 1\n",
            "[[ 0 -1  1]\n",
            " [-1  1  1]\n",
            " [-1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 13ms/step - loss: -1.3370\n",
            "action 0\n",
            "[[ 1 -1  1]\n",
            " [-1  1  1]\n",
            " [-1  1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "49 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1806\n",
            "action 0\n",
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4233\n",
            "action 7\n",
            "[[ 1  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2747\n",
            "action 5\n",
            "[[ 1  0  0]\n",
            " [ 0  0  1]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2641\n",
            "action 4\n",
            "[[ 1  0  0]\n",
            " [ 0 -1  1]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.3213\n",
            "action 6\n",
            "[[ 1  0  0]\n",
            " [ 0 -1  1]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0749\n",
            "action 2\n",
            "[[ 1  0 -1]\n",
            " [ 0 -1  1]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.4766\n",
            "action 3\n",
            "[[ 1  0 -1]\n",
            " [ 1 -1  1]\n",
            " [ 1 -1  0]]\n",
            "reward: 1\n",
            "done: True\n",
            "50 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1873\n",
            "action 3\n",
            "[[0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3573\n",
            "action 2\n",
            "[[ 0  0 -1]\n",
            " [ 1  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2875\n",
            "action 6\n",
            "[[ 0  0 -1]\n",
            " [ 1  0  0]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3175\n",
            "action 4\n",
            "[[ 0  0 -1]\n",
            " [ 1 -1  0]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2579\n",
            "action 8\n",
            "[[ 0  0 -1]\n",
            " [ 1 -1  0]\n",
            " [ 1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: -0.3084\n",
            "action 0\n",
            "[[-1  0 -1]\n",
            " [ 1 -1  0]\n",
            " [ 1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.1581\n",
            "action 1\n",
            "[[-1  1 -1]\n",
            " [ 1 -1  0]\n",
            " [ 1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.4144\n",
            "action 5\n",
            "[[-1  1 -1]\n",
            " [ 1 -1 -1]\n",
            " [ 1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.2251\n",
            "action 7\n",
            "[[-1  1 -1]\n",
            " [ 1 -1 -1]\n",
            " [ 1  1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "51 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1897\n",
            "action 2\n",
            "[[0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2237\n",
            "action 4\n",
            "[[ 0  0  1]\n",
            " [ 0 -1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2252\n",
            "action 7\n",
            "[[ 0  0  1]\n",
            " [ 0 -1  0]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2283\n",
            "action 6\n",
            "[[ 0  0  1]\n",
            " [ 0 -1  0]\n",
            " [-1  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2195\n",
            "action 8\n",
            "[[ 0  0  1]\n",
            " [ 0 -1  0]\n",
            " [-1  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.0918\n",
            "action 1\n",
            "[[ 0 -1  1]\n",
            " [ 0 -1  0]\n",
            " [-1  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0949\n",
            "action 0\n",
            "[[ 1 -1  1]\n",
            " [ 0 -1  0]\n",
            " [-1  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1011\n",
            "action 3\n",
            "[[ 1 -1  1]\n",
            " [-1 -1  0]\n",
            " [-1  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -5.0730e-06\n",
            "action 5\n",
            "[[ 1 -1  1]\n",
            " [-1 -1  1]\n",
            " [-1  1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "52 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1930\n",
            "action 1\n",
            "[[0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1940\n",
            "action 7\n",
            "[[ 0  1  0]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1169\n",
            "action 0\n",
            "[[ 1  1  0]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4627\n",
            "action 6\n",
            "[[ 1  1  0]\n",
            " [ 0  0  0]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.1851\n",
            "action 5\n",
            "[[ 1  1  0]\n",
            " [ 0  0  1]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2600\n",
            "action 3\n",
            "[[ 1  1  0]\n",
            " [-1  0  1]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.2825\n",
            "action 4\n",
            "[[ 1  1  0]\n",
            " [-1  1  1]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2137\n",
            "action 2\n",
            "[[ 1  1 -1]\n",
            " [-1  1  1]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -2.1239\n",
            "action 8\n",
            "[[ 1  1 -1]\n",
            " [-1  1  1]\n",
            " [-1 -1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "53 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2004\n",
            "action 8\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1546\n",
            "action 1\n",
            "[[ 0 -1  0]\n",
            " [ 0  0  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1795\n",
            "action 5\n",
            "[[ 0 -1  0]\n",
            " [ 0  0  1]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.0215\n",
            "action 3\n",
            "[[ 0 -1  0]\n",
            " [-1  0  1]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.1847\n",
            "action 7\n",
            "[[ 0 -1  0]\n",
            " [-1  0  1]\n",
            " [ 0  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.1341\n",
            "action 0\n",
            "[[-1 -1  0]\n",
            " [-1  0  1]\n",
            " [ 0  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.2620\n",
            "action 2\n",
            "[[-1 -1  1]\n",
            " [-1  0  1]\n",
            " [ 0  1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "54 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2032\n",
            "action 5\n",
            "[[0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4096\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 0  0  1]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.1514\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [ 0  1  1]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2023\n",
            "action 7\n",
            "[[ 0  0  0]\n",
            " [ 0  1  1]\n",
            " [ 0 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.2324\n",
            "action 2\n",
            "[[ 0  0  1]\n",
            " [ 0  1  1]\n",
            " [ 0 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0969\n",
            "action 3\n",
            "[[ 0  0  1]\n",
            " [-1  1  1]\n",
            " [ 0 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.4996\n",
            "action 6\n",
            "[[ 0  0  1]\n",
            " [-1  1  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "55 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2074\n",
            "action 8\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1584\n",
            "action 6\n",
            "[[ 0  0  0]\n",
            " [ 0  0  0]\n",
            " [-1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3118\n",
            "action 0\n",
            "[[ 1  0  0]\n",
            " [ 0  0  0]\n",
            " [-1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 12ms/step - loss: -0.0538\n",
            "action 1\n",
            "[[ 1 -1  0]\n",
            " [ 0  0  0]\n",
            " [-1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2107\n",
            "action 2\n",
            "[[ 1 -1  1]\n",
            " [ 0  0  0]\n",
            " [-1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -0.0045\n",
            "action 5\n",
            "[[ 1 -1  1]\n",
            " [ 0  0 -1]\n",
            " [-1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4021\n",
            "action 7\n",
            "[[ 1 -1  1]\n",
            " [ 0  0 -1]\n",
            " [-1  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1314\n",
            "action 3\n",
            "[[ 1 -1  1]\n",
            " [-1  0 -1]\n",
            " [-1  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1486\n",
            "action 4\n",
            "[[ 1 -1  1]\n",
            " [-1  1 -1]\n",
            " [-1  1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "56 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2135\n",
            "action 5\n",
            "[[0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4145\n",
            "action 3\n",
            "[[ 0  0  0]\n",
            " [-1  0  1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.3066\n",
            "action 1\n",
            "[[ 0  1  0]\n",
            " [-1  0  1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2845\n",
            "action 7\n",
            "[[ 0  1  0]\n",
            " [-1  0  1]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.5896\n",
            "action 6\n",
            "[[ 0  1  0]\n",
            " [-1  0  1]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.1939\n",
            "action 8\n",
            "[[ 0  1  0]\n",
            " [-1  0  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -1.7917\n",
            "action 4\n",
            "[[ 0  1  0]\n",
            " [-1  1  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.0635\n",
            "action 2\n",
            "[[ 0  1 -1]\n",
            " [-1  1  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -2.3723\n",
            "action 0\n",
            "[[ 1  1 -1]\n",
            " [-1  1  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "57 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2126\n",
            "action 8\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1604\n",
            "action 5\n",
            "[[ 0  0  0]\n",
            " [ 0  0 -1]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5174\n",
            "action 1\n",
            "[[ 0  1  0]\n",
            " [ 0  0 -1]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -0.4479\n",
            "action 7\n",
            "[[ 0  1  0]\n",
            " [ 0  0 -1]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3904\n",
            "action 6\n",
            "[[ 0  1  0]\n",
            " [ 0  0 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.8460\n",
            "action 3\n",
            "[[ 0  1  0]\n",
            " [-1  0 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0279\n",
            "action 2\n",
            "[[ 0  1  1]\n",
            " [-1  0 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -1.7191\n",
            "action 0\n",
            "[[-1  1  1]\n",
            " [-1  0 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -0.9224\n",
            "action 4\n",
            "[[-1  1  1]\n",
            " [-1  1 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "58 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2207\n",
            "action 6\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1626\n",
            "action 5\n",
            "[[ 0  0  0]\n",
            " [ 0  0 -1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4693\n",
            "action 3\n",
            "[[ 0  0  0]\n",
            " [ 1  0 -1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1617\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [ 1 -1 -1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4980\n",
            "action 0\n",
            "[[ 1  0  0]\n",
            " [ 1 -1 -1]\n",
            " [ 1  0  0]]\n",
            "reward: 1\n",
            "done: True\n",
            "59 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2203\n",
            "action 1\n",
            "[[0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2550\n",
            "action 7\n",
            "[[ 0  1  0]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1180\n",
            "action 2\n",
            "[[ 0  1  1]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2637\n",
            "action 6\n",
            "[[ 0  1  1]\n",
            " [ 0  0  0]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.1571\n",
            "action 5\n",
            "[[ 0  1  1]\n",
            " [ 0  0  1]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2975\n",
            "action 3\n",
            "[[ 0  1  1]\n",
            " [-1  0  1]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "q_values [[ 0.89953154  1.0849397   0.93058425  0.70367646 -0.81020176  0.38668635\n",
            "   1.1103628   0.7695897   0.7710389 ]]\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -1.3943\n",
            "action 0\n",
            "[[ 1  1  1]\n",
            " [-1  0  1]\n",
            " [-1 -1  0]]\n",
            "reward: 1\n",
            "done: True\n",
            "60 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2253\n",
            "action 2\n",
            "[[0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2466\n",
            "action 8\n",
            "[[ 0  0  1]\n",
            " [ 0  0  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0139\n",
            "action 7\n",
            "[[ 0  0  1]\n",
            " [ 0  0  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1586\n",
            "action 5\n",
            "[[ 0  0  1]\n",
            " [ 0  0 -1]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.0889\n",
            "action 6\n",
            "[[ 0  0  1]\n",
            " [ 0  0 -1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0443\n",
            "action 4\n",
            "[[ 0  0  1]\n",
            " [ 0 -1 -1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.5237\n",
            "action 0\n",
            "[[ 1  0  1]\n",
            " [ 0 -1 -1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3268\n",
            "action 3\n",
            "[[ 1  0  1]\n",
            " [-1 -1 -1]\n",
            " [ 1  1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "61 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2260\n",
            "action 5\n",
            "[[0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4182\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 0  0  1]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.1796\n",
            "action 0\n",
            "[[ 1  0  0]\n",
            " [ 0  0  1]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3297\n",
            "action 7\n",
            "[[ 1  0  0]\n",
            " [ 0  0  1]\n",
            " [ 0 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.5236\n",
            "action 2\n",
            "[[ 1  0  1]\n",
            " [ 0  0  1]\n",
            " [ 0 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2767\n",
            "action 3\n",
            "[[ 1  0  1]\n",
            " [-1  0  1]\n",
            " [ 0 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -2.3038\n",
            "action 6\n",
            "[[ 1  0  1]\n",
            " [-1  0  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.3787\n",
            "action 4\n",
            "[[ 1  0  1]\n",
            " [-1 -1  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -2.7165\n",
            "action 1\n",
            "[[ 1  1  1]\n",
            " [-1 -1  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "62 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2360\n",
            "action 7\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4039\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [ 0 -1  0]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5227\n",
            "action 3\n",
            "[[ 0  0  0]\n",
            " [ 1 -1  0]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.0525\n",
            "action 5\n",
            "[[ 0  0  0]\n",
            " [ 1 -1 -1]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5730\n",
            "action 0\n",
            "[[ 1  0  0]\n",
            " [ 1 -1 -1]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4469\n",
            "action 8\n",
            "[[ 1  0  0]\n",
            " [ 1 -1 -1]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2317\n",
            "action 2\n",
            "[[ 1  0  1]\n",
            " [ 1 -1 -1]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2477\n",
            "action 1\n",
            "[[ 1 -1  1]\n",
            " [ 1 -1 -1]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.6083\n",
            "action 6\n",
            "[[ 1 -1  1]\n",
            " [ 1 -1 -1]\n",
            " [ 1  1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "63 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2409\n",
            "action 8\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1650\n",
            "action 7\n",
            "[[ 0  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3020\n",
            "action 2\n",
            "[[ 0  0  1]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.1835\n",
            "action 3\n",
            "[[ 0  0  1]\n",
            " [-1  0  0]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.0827\n",
            "action 5\n",
            "[[ 0  0  1]\n",
            " [-1  0  1]\n",
            " [ 0 -1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "64 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2442\n",
            "action 0\n",
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4856\n",
            "action 1\n",
            "[[ 1 -1  0]\n",
            " [ 0  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2342\n",
            "action 2\n",
            "[[ 1 -1  1]\n",
            " [ 0  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.0280\n",
            "action 8\n",
            "[[ 1 -1  1]\n",
            " [ 0  0  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -0.5603\n",
            "action 4\n",
            "[[ 1 -1  1]\n",
            " [ 0  1  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -0.1429\n",
            "action 5\n",
            "[[ 1 -1  1]\n",
            " [ 0  1 -1]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.5367\n",
            "action 3\n",
            "[[ 1 -1  1]\n",
            " [ 1  1 -1]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.0872\n",
            "action 6\n",
            "[[ 1 -1  1]\n",
            " [ 1  1 -1]\n",
            " [-1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -0.8248\n",
            "action 7\n",
            "[[ 1 -1  1]\n",
            " [ 1  1 -1]\n",
            " [-1  1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "65 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2465\n",
            "action 6\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1654\n",
            "action 1\n",
            "[[ 0 -1  0]\n",
            " [ 0  0  0]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2446\n",
            "action 8\n",
            "[[ 0 -1  0]\n",
            " [ 0  0  0]\n",
            " [ 1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.4107\n",
            "action 5\n",
            "[[ 0 -1  0]\n",
            " [ 0  0 -1]\n",
            " [ 1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3262\n",
            "action 7\n",
            "[[ 0 -1  0]\n",
            " [ 0  0 -1]\n",
            " [ 1  1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "66 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2528\n",
            "action 0\n",
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4912\n",
            "action 4\n",
            "[[ 1  0  0]\n",
            " [ 0 -1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3114\n",
            "action 8\n",
            "[[ 1  0  0]\n",
            " [ 0 -1  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1778\n",
            "action 2\n",
            "[[ 1  0 -1]\n",
            " [ 0 -1  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5306\n",
            "action 6\n",
            "[[ 1  0 -1]\n",
            " [ 0 -1  0]\n",
            " [ 1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "q_values [[ 0.9438384   0.7793593  -0.34939483  1.2170017   0.90474784  0.7403898\n",
            "   0.7007217   1.0826123   0.40031263]]\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.7824\n",
            "action 3\n",
            "[[ 1  0 -1]\n",
            " [-1 -1  0]\n",
            " [ 1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0511\n",
            "action 5\n",
            "[[ 1  0 -1]\n",
            " [-1 -1  1]\n",
            " [ 1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -1.5573\n",
            "action 7\n",
            "[[ 1  0 -1]\n",
            " [-1 -1  1]\n",
            " [ 1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -1.2418\n",
            "action 1\n",
            "[[ 1  1 -1]\n",
            " [-1 -1  1]\n",
            " [ 1 -1  1]]\n",
            "reward: -1\n",
            "done: True\n",
            "67 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2533\n",
            "action 5\n",
            "[[0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4328\n",
            "action 2\n",
            "[[ 0  0 -1]\n",
            " [ 0  0  1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0738\n",
            "action 6\n",
            "[[ 0  0 -1]\n",
            " [ 0  0  1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0293\n",
            "action 8\n",
            "[[ 0  0 -1]\n",
            " [ 0  0  1]\n",
            " [ 1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.3104\n",
            "action 4\n",
            "[[ 0  0 -1]\n",
            " [ 0  1  1]\n",
            " [ 1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.0883\n",
            "action 3\n",
            "[[ 0  0 -1]\n",
            " [-1  1  1]\n",
            " [ 1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -1.5651\n",
            "action 0\n",
            "[[ 1  0 -1]\n",
            " [-1  1  1]\n",
            " [ 1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1197\n",
            "action 7\n",
            "[[ 1  0 -1]\n",
            " [-1  1  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 15ms/step - loss: -2.5336\n",
            "action 1\n",
            "[[ 1  1 -1]\n",
            " [-1  1  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "68 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2571\n",
            "action 3\n",
            "[[0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4567\n",
            "action 0\n",
            "[[-1  0  0]\n",
            " [ 1  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3591\n",
            "action 1\n",
            "[[-1  1  0]\n",
            " [ 1  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2568\n",
            "action 6\n",
            "[[-1  1  0]\n",
            " [ 1  0  0]\n",
            " [-1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4390\n",
            "action 4\n",
            "[[-1  1  0]\n",
            " [ 1  1  0]\n",
            " [-1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.5503\n",
            "action 5\n",
            "[[-1  1  0]\n",
            " [ 1  1 -1]\n",
            " [-1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0566\n",
            "action 7\n",
            "[[-1  1  0]\n",
            " [ 1  1 -1]\n",
            " [-1  1  0]]\n",
            "reward: 1\n",
            "done: True\n",
            "69 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2621\n",
            "action 2\n",
            "[[0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2582\n",
            "action 0\n",
            "[[-1  0  1]\n",
            " [ 0  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3167\n",
            "action 8\n",
            "[[-1  0  1]\n",
            " [ 0  0  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.1214\n",
            "action 5\n",
            "[[-1  0  1]\n",
            " [ 0  0 -1]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4789\n",
            "action 6\n",
            "[[-1  0  1]\n",
            " [ 0  0 -1]\n",
            " [ 1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "q_values [[ 0.5248782   0.7630896  -0.8066377   0.6279366   1.190253    0.8380135\n",
            "   0.8460432   0.47083464  0.24157117]]\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -1.2584\n",
            "action 4\n",
            "[[-1  0  1]\n",
            " [ 0 -1 -1]\n",
            " [ 1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0941\n",
            "action 1\n",
            "[[-1  1  1]\n",
            " [ 0 -1 -1]\n",
            " [ 1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -1.6204\n",
            "action 7\n",
            "[[-1  1  1]\n",
            " [ 0 -1 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.3678\n",
            "action 3\n",
            "[[-1  1  1]\n",
            " [ 1 -1 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: -1\n",
            "done: True\n",
            "70 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2613\n",
            "action 3\n",
            "[[0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4643\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [ 1 -1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4536\n",
            "action 7\n",
            "[[ 0  0  0]\n",
            " [ 1 -1  0]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1993\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 1 -1  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2731\n",
            "action 1\n",
            "[[ 0  1  0]\n",
            " [ 1 -1  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2043\n",
            "action 5\n",
            "[[ 0  1  0]\n",
            " [ 1 -1 -1]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2361\n",
            "action 0\n",
            "[[ 1  1  0]\n",
            " [ 1 -1 -1]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4337\n",
            "action 2\n",
            "[[ 1  1 -1]\n",
            " [ 1 -1 -1]\n",
            " [ 0  1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "71 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2667\n",
            "action 4\n",
            "[[0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1881\n",
            "action 6\n",
            "[[ 0  0  0]\n",
            " [ 0  1  0]\n",
            " [-1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2901\n",
            "action 0\n",
            "[[ 1  0  0]\n",
            " [ 0  1  0]\n",
            " [-1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2535\n",
            "action 2\n",
            "[[ 1  0 -1]\n",
            " [ 0  1  0]\n",
            " [-1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.1289\n",
            "action 1\n",
            "[[ 1  1 -1]\n",
            " [ 0  1  0]\n",
            " [-1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4994\n",
            "action 5\n",
            "[[ 1  1 -1]\n",
            " [ 0  1 -1]\n",
            " [-1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.6134\n",
            "action 3\n",
            "[[ 1  1 -1]\n",
            " [ 1  1 -1]\n",
            " [-1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4373\n",
            "action 8\n",
            "[[ 1  1 -1]\n",
            " [ 1  1 -1]\n",
            " [-1  0 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "72 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2643\n",
            "action 1\n",
            "[[0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4421\n",
            "action 8\n",
            "[[ 0  1  0]\n",
            " [ 0  0  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.1001\n",
            "action 3\n",
            "[[ 0  1  0]\n",
            " [ 1  0  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5023\n",
            "action 2\n",
            "[[ 0  1 -1]\n",
            " [ 1  0  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.3126\n",
            "action 6\n",
            "[[ 0  1 -1]\n",
            " [ 1  0  0]\n",
            " [ 1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.4776\n",
            "action 4\n",
            "[[ 0  1 -1]\n",
            " [ 1 -1  0]\n",
            " [ 1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.8809\n",
            "action 0\n",
            "[[ 1  1 -1]\n",
            " [ 1 -1  0]\n",
            " [ 1  0 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "73 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2719\n",
            "action 3\n",
            "[[0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4893\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [ 1 -1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4523\n",
            "action 1\n",
            "[[ 0  1  0]\n",
            " [ 1 -1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2292\n",
            "action 2\n",
            "[[ 0  1 -1]\n",
            " [ 1 -1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1887\n",
            "action 0\n",
            "[[ 1  1 -1]\n",
            " [ 1 -1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "q_values [[ 0.63369817  0.68108267 -0.05869263  0.99643004  0.711095    0.70854986\n",
            "   0.6010673   1.343248    0.54184955]]\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.2516\n",
            "action 7\n",
            "[[ 1  1 -1]\n",
            " [ 1 -1  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.4891\n",
            "action 5\n",
            "[[ 1  1 -1]\n",
            " [ 1 -1  1]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -1.5814\n",
            "action 8\n",
            "[[ 1  1 -1]\n",
            " [ 1 -1  1]\n",
            " [ 0 -1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -3.1615\n",
            "action 6\n",
            "[[ 1  1 -1]\n",
            " [ 1 -1  1]\n",
            " [ 1 -1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "74 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2738\n",
            "action 7\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4651\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1043\n",
            "action 6\n",
            "[[ 0  0  0]\n",
            " [ 0  0  0]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3228\n",
            "action 0\n",
            "[[-1  0  0]\n",
            " [ 0  0  0]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.2075\n",
            "action 4\n",
            "[[-1  0  0]\n",
            " [ 0  1  0]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.2074\n",
            "action 5\n",
            "[[-1  0  0]\n",
            " [ 0  1 -1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.5038\n",
            "action 2\n",
            "[[-1  0  1]\n",
            " [ 0  1 -1]\n",
            " [ 1  1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "75 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2779\n",
            "action 5\n",
            "[[0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4352\n",
            "action 7\n",
            "[[ 0  0  0]\n",
            " [ 0  0  1]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.1367\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 0  0  1]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.0378\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [ 0 -1  1]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.1835\n",
            "action 3\n",
            "[[ 0  0  0]\n",
            " [ 1 -1  1]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.8739\n",
            "action 0\n",
            "[[-1  0  0]\n",
            " [ 1 -1  1]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.4045\n",
            "action 1\n",
            "[[-1  1  0]\n",
            " [ 1 -1  1]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -2.2863\n",
            "action 2\n",
            "[[-1  1 -1]\n",
            " [ 1 -1  1]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: -1.4544\n",
            "action 6\n",
            "[[-1  1 -1]\n",
            " [ 1 -1  1]\n",
            " [ 1 -1  1]]\n",
            "reward: -1\n",
            "done: True\n",
            "76 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2765\n",
            "action 0\n",
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5148\n",
            "action 2\n",
            "[[ 1  0 -1]\n",
            " [ 0  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3749\n",
            "action 6\n",
            "[[ 1  0 -1]\n",
            " [ 0  0  0]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.0461\n",
            "action 4\n",
            "[[ 1  0 -1]\n",
            " [ 0 -1  0]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.0129\n",
            "action 7\n",
            "[[ 1  0 -1]\n",
            " [ 0 -1  0]\n",
            " [ 1  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.3465\n",
            "action 5\n",
            "[[ 1  0 -1]\n",
            " [ 0 -1 -1]\n",
            " [ 1  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4374\n",
            "action 8\n",
            "[[ 1  0 -1]\n",
            " [ 0 -1 -1]\n",
            " [ 1  1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "77 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2823\n",
            "action 7\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4688\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0972\n",
            "action 1\n",
            "[[ 0  1  0]\n",
            " [ 0  0  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5115\n",
            "action 6\n",
            "[[ 0  1  0]\n",
            " [ 0  0  0]\n",
            " [-1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.2801\n",
            "action 3\n",
            "[[ 0  1  0]\n",
            " [ 1  0  0]\n",
            " [-1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3680\n",
            "action 4\n",
            "[[ 0  1  0]\n",
            " [ 1 -1  0]\n",
            " [-1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.7728\n",
            "action 0\n",
            "[[ 1  1  0]\n",
            " [ 1 -1  0]\n",
            " [-1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3764\n",
            "action 5\n",
            "[[ 1  1  0]\n",
            " [ 1 -1 -1]\n",
            " [-1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.7686\n",
            "action 2\n",
            "[[ 1  1  1]\n",
            " [ 1 -1 -1]\n",
            " [-1  1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "78 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3262\n",
            "action 4\n",
            "[[0 0 0]\n",
            " [0 1 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2195\n",
            "action 3\n",
            "[[ 0  0  0]\n",
            " [-1  1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1425\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [-1  1  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.3958\n",
            "action 1\n",
            "[[ 0 -1  0]\n",
            " [-1  1  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0393\n",
            "action 6\n",
            "[[ 0 -1  0]\n",
            " [-1  1  0]\n",
            " [ 1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -1.3231\n",
            "action 7\n",
            "[[ 0 -1  0]\n",
            " [-1  1  0]\n",
            " [ 1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: -1.0587\n",
            "action 2\n",
            "[[ 0 -1  1]\n",
            " [-1  1  0]\n",
            " [ 1 -1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "79 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2914\n",
            "action 0\n",
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5101\n",
            "action 8\n",
            "[[ 1  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.2166\n",
            "action 7\n",
            "[[ 1  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5045\n",
            "action 2\n",
            "[[ 1  0 -1]\n",
            " [ 0  0  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.2921\n",
            "action 5\n",
            "[[ 1  0 -1]\n",
            " [ 0  0  1]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3303\n",
            "action 3\n",
            "[[ 1  0 -1]\n",
            " [-1  0  1]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.5902\n",
            "action 6\n",
            "[[ 1  0 -1]\n",
            " [-1  0  1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1218\n",
            "action 1\n",
            "[[ 1 -1 -1]\n",
            " [-1  0  1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.6119\n",
            "action 4\n",
            "[[ 1 -1 -1]\n",
            " [-1  1  1]\n",
            " [ 1  1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "80 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2924\n",
            "action 3\n",
            "[[0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5071\n",
            "action 6\n",
            "[[ 0  0  0]\n",
            " [ 1  0  0]\n",
            " [-1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3653\n",
            "action 5\n",
            "[[ 0  0  0]\n",
            " [ 1  0  1]\n",
            " [-1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3149\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 1  0  1]\n",
            " [-1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -0.2650\n",
            "action 7\n",
            "[[ 0  0  0]\n",
            " [ 1  0  1]\n",
            " [-1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1019\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [ 1 -1  1]\n",
            " [-1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -0.7530\n",
            "action 1\n",
            "[[ 0  1  0]\n",
            " [ 1 -1  1]\n",
            " [-1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.0174\n",
            "action 0\n",
            "[[-1  1  0]\n",
            " [ 1 -1  1]\n",
            " [-1  1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "81 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2940\n",
            "action 2\n",
            "[[0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2588\n",
            "action 0\n",
            "[[-1  0  1]\n",
            " [ 0  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3097\n",
            "action 8\n",
            "[[-1  0  1]\n",
            " [ 0  0  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.1717\n",
            "action 3\n",
            "[[-1  0  1]\n",
            " [-1  0  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.0297\n",
            "action 7\n",
            "[[-1  0  1]\n",
            " [-1  0  0]\n",
            " [ 0  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.6820\n",
            "action 6\n",
            "[[-1  0  1]\n",
            " [-1  0  0]\n",
            " [-1  1  1]]\n",
            "reward: -1\n",
            "done: True\n",
            "82 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2956\n",
            "action 0\n",
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5157\n",
            "action 3\n",
            "[[ 1  0  0]\n",
            " [-1  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "q_values [[ 0.909553    0.7635294   0.72175854  0.6603418  -0.29020324  0.5442878\n",
            "   0.65091306  0.69053817  0.6212238 ]]\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0248\n",
            "action 1\n",
            "[[ 1  1  0]\n",
            " [-1  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4986\n",
            "action 8\n",
            "[[ 1  1  0]\n",
            " [-1  0  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -3.3805\n",
            "action 6\n",
            "[[ 1  1  0]\n",
            " [-1  0  0]\n",
            " [ 1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3015\n",
            "action 5\n",
            "[[ 1  1  0]\n",
            " [-1  0 -1]\n",
            " [ 1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -2.8039\n",
            "action 7\n",
            "[[ 1  1  0]\n",
            " [-1  0 -1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0760\n",
            "action 2\n",
            "[[ 1  1 -1]\n",
            " [-1  0 -1]\n",
            " [ 1  1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "83 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2986\n",
            "action 0\n",
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5422\n",
            "action 4\n",
            "[[ 1  0  0]\n",
            " [ 0 -1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2760\n",
            "action 5\n",
            "[[ 1  0  0]\n",
            " [ 0 -1  1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1406\n",
            "action 2\n",
            "[[ 1  0 -1]\n",
            " [ 0 -1  1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.3947\n",
            "action 3\n",
            "[[ 1  0 -1]\n",
            " [ 1 -1  1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 14ms/step - loss: -0.9859\n",
            "action 7\n",
            "[[ 1  0 -1]\n",
            " [ 1 -1  1]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -1.3334\n",
            "action 6\n",
            "[[ 1  0 -1]\n",
            " [ 1 -1  1]\n",
            " [ 1 -1  0]]\n",
            "reward: 1\n",
            "done: True\n",
            "84 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3041\n",
            "action 0\n",
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5855\n",
            "action 6\n",
            "[[ 1  0  0]\n",
            " [ 0  0  0]\n",
            " [-1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1120\n",
            "action 3\n",
            "[[ 1  0  0]\n",
            " [ 1  0  0]\n",
            " [-1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5434\n",
            "action 7\n",
            "[[ 1  0  0]\n",
            " [ 1  0  0]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.2460\n",
            "action 1\n",
            "[[ 1  1  0]\n",
            " [ 1  0  0]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3960\n",
            "action 5\n",
            "[[ 1  1  0]\n",
            " [ 1  0 -1]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -0.9957\n",
            "action 4\n",
            "[[ 1  1  0]\n",
            " [ 1  1 -1]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1662\n",
            "action 2\n",
            "[[ 1  1 -1]\n",
            " [ 1  1 -1]\n",
            " [-1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -2.4298\n",
            "action 8\n",
            "[[ 1  1 -1]\n",
            " [ 1  1 -1]\n",
            " [-1 -1  1]]\n",
            "reward: 1\n",
            "done: True\n",
            "85 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3100\n",
            "action 3\n",
            "[[0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5858\n",
            "action 0\n",
            "[[-1  0  0]\n",
            " [ 1  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3769\n",
            "action 5\n",
            "[[-1  0  0]\n",
            " [ 1  0  1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2731\n",
            "action 2\n",
            "[[-1  0 -1]\n",
            " [ 1  0  1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1609\n",
            "action 6\n",
            "[[-1  0 -1]\n",
            " [ 1  0  1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "q_values [[ 1.0934123   0.72389907 -0.11463971  1.276769    1.6670294   1.0163507\n",
            "   0.508935    0.93720317  0.9357251 ]]\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.7863\n",
            "action 4\n",
            "[[-1  0 -1]\n",
            " [ 1 -1  1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -1.0701\n",
            "action 1\n",
            "[[-1  1 -1]\n",
            " [ 1 -1  1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -4.5077\n",
            "action 7\n",
            "[[-1  1 -1]\n",
            " [ 1 -1  1]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -2.7137\n",
            "action 8\n",
            "[[-1  1 -1]\n",
            " [ 1 -1  1]\n",
            " [ 1 -1  1]]\n",
            "reward: -1\n",
            "done: True\n",
            "86 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3070\n",
            "action 7\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5855\n",
            "action 0\n",
            "[[-1  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4558\n",
            "action 2\n",
            "[[-1  0  1]\n",
            " [ 0  0  0]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1478\n",
            "action 3\n",
            "[[-1  0  1]\n",
            " [-1  0  0]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 13ms/step - loss: -0.4491\n",
            "action 1\n",
            "[[-1  1  1]\n",
            " [-1  0  0]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -0.0985\n",
            "action 6\n",
            "[[-1  1  1]\n",
            " [-1  0  0]\n",
            " [-1  1  0]]\n",
            "reward: -1\n",
            "done: True\n",
            "87 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3085\n",
            "action 7\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5909\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0423\n",
            "action 2\n",
            "[[ 0  0  1]\n",
            " [ 0  0  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5330\n",
            "action 6\n",
            "[[ 0  0  1]\n",
            " [ 0  0  0]\n",
            " [-1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.8426\n",
            "action 5\n",
            "[[ 0  0  1]\n",
            " [ 0  0  1]\n",
            " [-1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3143\n",
            "action 4\n",
            "[[ 0  0  1]\n",
            " [ 0 -1  1]\n",
            " [-1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -1.8370\n",
            "action 0\n",
            "[[ 1  0  1]\n",
            " [ 0 -1  1]\n",
            " [-1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2878\n",
            "action 1\n",
            "[[ 1 -1  1]\n",
            " [ 0 -1  1]\n",
            " [-1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -2.8576\n",
            "action 3\n",
            "[[ 1 -1  1]\n",
            " [ 1 -1  1]\n",
            " [-1  1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "88 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3122\n",
            "action 6\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3949\n",
            "action 5\n",
            "[[ 0  0  0]\n",
            " [ 0  0 -1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5109\n",
            "action 7\n",
            "[[ 0  0  0]\n",
            " [ 0  0 -1]\n",
            " [ 1  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3902\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 0  0 -1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.1990\n",
            "action 1\n",
            "[[ 0  1  0]\n",
            " [ 0  0 -1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1098\n",
            "action 4\n",
            "[[ 0  1  0]\n",
            " [ 0 -1 -1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.4881\n",
            "action 2\n",
            "[[ 0  1  1]\n",
            " [ 0 -1 -1]\n",
            " [ 1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.5437\n",
            "action 3\n",
            "[[ 0  1  1]\n",
            " [-1 -1 -1]\n",
            " [ 1  1 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "89 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3150\n",
            "action 0\n",
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6294\n",
            "action 7\n",
            "[[ 1  0  0]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2923\n",
            "action 4\n",
            "[[ 1  0  0]\n",
            " [ 0  1  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3809\n",
            "action 2\n",
            "[[ 1  0 -1]\n",
            " [ 0  1  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.0716\n",
            "action 3\n",
            "[[ 1  0 -1]\n",
            " [ 1  1  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -1.2331\n",
            "action 1\n",
            "[[ 1 -1 -1]\n",
            " [ 1  1  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.2973\n",
            "action 5\n",
            "[[ 1 -1 -1]\n",
            " [ 1  1  1]\n",
            " [ 0 -1  0]]\n",
            "reward: 1\n",
            "done: True\n",
            "90 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3215\n",
            "action 3\n",
            "[[0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6321\n",
            "action 2\n",
            "[[ 0  0 -1]\n",
            " [ 1  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3387\n",
            "action 4\n",
            "[[ 0  0 -1]\n",
            " [ 1  1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0019\n",
            "action 0\n",
            "[[-1  0 -1]\n",
            " [ 1  1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0031\n",
            "action 5\n",
            "[[-1  0 -1]\n",
            " [ 1  1  1]\n",
            " [ 0  0  0]]\n",
            "reward: 1\n",
            "done: True\n",
            "91 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3222\n",
            "action 5\n",
            "[[0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5608\n",
            "action 0\n",
            "[[-1  0  0]\n",
            " [ 0  0  1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1460\n",
            "action 6\n",
            "[[-1  0  0]\n",
            " [ 0  0  1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0486\n",
            "action 8\n",
            "[[-1  0  0]\n",
            " [ 0  0  1]\n",
            " [ 1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.5417\n",
            "action 1\n",
            "[[-1  1  0]\n",
            " [ 0  0  1]\n",
            " [ 1  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.2268\n",
            "action 4\n",
            "[[-1  1  0]\n",
            " [ 0 -1  1]\n",
            " [ 1  0 -1]]\n",
            "reward: -1\n",
            "done: True\n",
            "92 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3199\n",
            "action 7\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6087\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [ 0 -1  0]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5654\n",
            "action 5\n",
            "[[ 0  0  0]\n",
            " [ 0 -1  1]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3550\n",
            "action 2\n",
            "[[ 0  0 -1]\n",
            " [ 0 -1  1]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -0.1321\n",
            "action 3\n",
            "[[ 0  0 -1]\n",
            " [ 1 -1  1]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.7111\n",
            "action 0\n",
            "[[-1  0 -1]\n",
            " [ 1 -1  1]\n",
            " [ 0  1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.2785\n",
            "action 8\n",
            "[[-1  0 -1]\n",
            " [ 1 -1  1]\n",
            " [ 0  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -2.7260\n",
            "action 6\n",
            "[[-1  0 -1]\n",
            " [ 1 -1  1]\n",
            " [-1  1  1]]\n",
            "reward: -1\n",
            "done: True\n",
            "93 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3211\n",
            "action 2\n",
            "[[0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5178\n",
            "action 0\n",
            "[[-1  0  1]\n",
            " [ 0  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3241\n",
            "action 4\n",
            "[[-1  0  1]\n",
            " [ 0  1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0515\n",
            "action 7\n",
            "[[-1  0  1]\n",
            " [ 0  1  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -0.0095\n",
            "action 6\n",
            "[[-1  0  1]\n",
            " [ 0  1  0]\n",
            " [ 1 -1  0]]\n",
            "reward: 1\n",
            "done: True\n",
            "94 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "q_values [[ 0.16334616  0.19856443  0.17153287  0.120992   -0.03222505  0.13185133\n",
            "   0.13489595  0.14671472  0.15020691]]\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3251\n",
            "action 1\n",
            "[[0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6472\n",
            "action 2\n",
            "[[ 0  1 -1]\n",
            " [ 0  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2115\n",
            "action 0\n",
            "[[ 1  1 -1]\n",
            " [ 0  0  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "q_values [[0.6459137  0.74090797 0.36872858 0.8436355  0.6431267  0.8915317\n",
            "  0.54390156 1.223145   0.9095762 ]]\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1001\n",
            "action 7\n",
            "[[ 1  1 -1]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -0.5738\n",
            "action 8\n",
            "[[ 1  1 -1]\n",
            " [ 0  0  0]\n",
            " [ 0 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.3618\n",
            "action 6\n",
            "[[ 1  1 -1]\n",
            " [ 0  0  0]\n",
            " [-1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.4996\n",
            "action 5\n",
            "[[ 1  1 -1]\n",
            " [ 0  0  1]\n",
            " [-1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -1.3022\n",
            "action 4\n",
            "[[ 1  1 -1]\n",
            " [ 0 -1  1]\n",
            " [-1 -1  1]]\n",
            "reward: -1\n",
            "done: True\n",
            "95 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3255\n",
            "action 1\n",
            "[[0 1 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6498\n",
            "action 8\n",
            "[[ 0  1  0]\n",
            " [ 0  0  0]\n",
            " [ 0  0 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -0.2663\n",
            "action 7\n",
            "[[ 0  1  0]\n",
            " [ 0  0  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6198\n",
            "action 3\n",
            "[[ 0  1  0]\n",
            " [-1  0  0]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -2.0814\n",
            "action 5\n",
            "[[ 0  1  0]\n",
            " [-1  0  1]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "q_values [[0.4064297  0.9409051  0.2855511  0.6841709  0.9883509  1.0289081\n",
            "  0.7128343  0.7331262  0.46570355]]\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4015\n",
            "action 4\n",
            "[[ 0  1  0]\n",
            " [-1 -1  1]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -3.5432\n",
            "action 0\n",
            "[[ 1  1  0]\n",
            " [-1 -1  1]\n",
            " [ 0  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 5ms/step - loss: -1.0565\n",
            "action 6\n",
            "[[ 1  1  0]\n",
            " [-1 -1  1]\n",
            " [-1  1 -1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 17ms/step - loss: -7.2646\n",
            "action 2\n",
            "[[ 1  1  1]\n",
            " [-1 -1  1]\n",
            " [-1  1 -1]]\n",
            "reward: 1\n",
            "done: True\n",
            "96 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3336\n",
            "action 3\n",
            "[[0 0 0]\n",
            " [1 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6584\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [ 1 -1  0]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4927\n",
            "action 8\n",
            "[[ 0  0  0]\n",
            " [ 1 -1  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0160\n",
            "action 2\n",
            "[[ 0  0 -1]\n",
            " [ 1 -1  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2205\n",
            "action 7\n",
            "[[ 0  0 -1]\n",
            " [ 1 -1  0]\n",
            " [ 0  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: -1.7068\n",
            "action 0\n",
            "[[-1  0 -1]\n",
            " [ 1 -1  0]\n",
            " [ 0  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.2040\n",
            "action 5\n",
            "[[-1  0 -1]\n",
            " [ 1 -1  1]\n",
            " [ 0  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -3.8659\n",
            "action 1\n",
            "[[-1 -1 -1]\n",
            " [ 1 -1  1]\n",
            " [ 0  1  1]]\n",
            "reward: -1\n",
            "done: True\n",
            "97 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3277\n",
            "action 0\n",
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6580\n",
            "action 5\n",
            "[[ 1  0  0]\n",
            " [ 0  0 -1]\n",
            " [ 0  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5963\n",
            "action 6\n",
            "[[ 1  0  0]\n",
            " [ 0  0 -1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3520\n",
            "action 7\n",
            "[[ 1  0  0]\n",
            " [ 0  0 -1]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2165\n",
            "action 1\n",
            "[[ 1  1  0]\n",
            " [ 0  0 -1]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 8ms/step - loss: -1.6260\n",
            "action 3\n",
            "[[ 1  1  0]\n",
            " [-1  0 -1]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -1.7662\n",
            "action 8\n",
            "[[ 1  1  0]\n",
            " [-1  0 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 7ms/step - loss: -4.8780\n",
            "action 4\n",
            "[[ 1  1  0]\n",
            " [-1 -1 -1]\n",
            " [ 1 -1  1]]\n",
            "reward: -1\n",
            "done: True\n",
            "98 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3266\n",
            "action 8\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5720\n",
            "action 3\n",
            "[[ 0  0  0]\n",
            " [-1  0  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3352\n",
            "action 2\n",
            "[[ 0  0  1]\n",
            " [-1  0  0]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.3989\n",
            "action 5\n",
            "[[ 0  0  1]\n",
            " [-1  0 -1]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.1614\n",
            "action 1\n",
            "[[ 0  1  1]\n",
            " [-1  0 -1]\n",
            " [ 0  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.9443\n",
            "action 6\n",
            "[[ 0  1  1]\n",
            " [-1  0 -1]\n",
            " [-1  0  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -1.3671\n",
            "action 7\n",
            "[[ 0  1  1]\n",
            " [-1  0 -1]\n",
            " [-1  1  1]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 16ms/step - loss: -1.0420\n",
            "action 4\n",
            "[[ 0  1  1]\n",
            " [-1 -1 -1]\n",
            " [-1  1  1]]\n",
            "reward: -1\n",
            "done: True\n",
            "99 ----------------------------------------------------------------------------------------------------\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3276\n",
            "action 6\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5683\n",
            "action 5\n",
            "[[ 0  0  0]\n",
            " [ 0  0 -1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5020\n",
            "action 4\n",
            "[[ 0  0  0]\n",
            " [ 0  1 -1]\n",
            " [ 1  0  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: -0.0333\n",
            "action 7\n",
            "[[ 0  0  0]\n",
            " [ 0  1 -1]\n",
            " [ 1 -1  0]]\n",
            "reward: 0\n",
            "done: False\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1652\n",
            "action 2\n",
            "[[ 0  0  1]\n",
            " [ 0  1 -1]\n",
            " [ 1 -1  0]]\n",
            "reward: 1\n",
            "done: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model_1')"
      ],
      "metadata": {
        "id": "huubVGnBqZHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd7a5ca3-e943-4938-ec5e-8514d00634b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пробуем сыграть с ботом (бот ходит первым)"
      ],
      "metadata": {
        "id": "2MxemcGVMgwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = TicTacToeEnvironment()\n",
        "done = False\n",
        "while not done:\n",
        "        action = choose_action(env.state, epsilon, model_1)\n",
        "        print(\"action\", action)\n",
        "        next_state, reward, done = env.step_game_player(action)\n",
        "        print(next_state)\n",
        "        x, y = input(\"Введите координаты через пробел: \").split()\n",
        "        x = int(x)\n",
        "        y = int(y)\n",
        "        next_state[x][y] = -1\n",
        "        update_q_function(env.state, action, reward, next_state, alpha, gamma, model_1)\n",
        "        print('win', env.get_winner() )\n",
        "        if env.get_winner() == None:\n",
        "          update_q_function(env.state, action, reward, next_state, alpha, gamma, model_1)\n",
        "        else:\n",
        "          done = True"
      ],
      "metadata": {
        "id": "-nCYxktMMdyJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "aecbd05d-8394-4d0e-a280-50444eea21f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action 2\n",
            "[[0 0 1]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "Введите координаты через пробел: 1 1\n",
            "[[ 0  0  1]\n",
            " [ 0 -1  0]\n",
            " [ 0  0  0]]\n",
            "win None\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1705\n",
            "action 4\n",
            "[[0 0 1]\n",
            " [0 1 0]\n",
            " [0 0 0]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-58e5dc4a1d0c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_game_player\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Введите координаты через пробел: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wJyo81hVgP4w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}